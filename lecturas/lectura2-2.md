# Personal opinion on:

### Rendle, S., Freudenthaler, C., Gantner, Z., & Schmidt-Thieme, L. (2009). BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (pp. 452-461). AUAI Press.

In this paper, the authors propose a new way of training (loss function) for implicit feedback recommender systems, based on a bayesian approach. Their main goal is to have a loss function that is optimized for learning actual rankings, and not just learning to predict 1 on the elements that were present in <img src="https://render.githubusercontent.com/render/math?math=S"> (training data) and 0 on the elements that were not present on <img src="https://render.githubusercontent.com/render/math?math=S">. As they point out, one of the main problems in the lack of negative feedback on implicit feedback datasets. This happens because implicit feedback gathers data based on the users actions, but it doesn't know what the reaction of the user to that said action was, so, for example, if a user buys an item in an online shop, the data is gathered and the system knows the user bought said item, but it doesn't know if the user actually liked this item, or maybe he disliked it a lot.

As a solution to this problem, they authors propose to take a different approach to data. They create a training data <img src="https://render.githubusercontent.com/render/math?math=D_S := U x I x I">, which acts as an approximation to a ranking, where they assume that if a user has interacted with object 1 but not with object 2, then the user prefers object 1 over 2. With this they are left with both positive and negative pairs, and also missing values, which are the ones the system should aim to learn to rank. In my opinion, while this approach resulted in better results than the traditional methods, this is not really solving the problem of the system learning to predict 1 to objects in <img src="https://render.githubusercontent.com/render/math?math=S"> and 0 otherwise, because, now our system is learning to rank items that were in <img src="https://render.githubusercontent.com/render/math?math=S"> higher than items that were not present in it (as the training data suggests).

After this, the BPR optimization criterion is explained, as well as the BPR learning algorithm. An interesting approach the autors took here is the choice to go for a bootstrap sampling method. There's a theoretical explanation as to why this is better, but actual testing in models, compared to a regular sampling method (all samples, without replacement) would be interesting to see. It is clear, though, that this approach converges much faster, as it can be seen in the Figure 5.

Finally, they move on to explaining how to use their proposed method with two of the most popular models (at the time): kNN and matrix factorization. After this they explain the two datasets used in the evaluation of their models. In this datasets, for the second one, they point out that they used a subsample such that every user had at least 10 items, and each item at least 10 users. There is no such information for the first dataset, but a different subsample method would be interesting to see too, to be able to see how the models behave when confronted to users or items that are relatively new (not necessarily zero interactions as in a cold start, but at least items and users with interactions as little as two).

After that, they move on to discuss the results obtained. Here we can see how the models using the BPR optimization method outperformed every other model compared to.  We can see an really good comparison between the proposed method and a variety of other method considered state of the art at the time. We can also see that they chose to compare the method to some baseline models such as most popular, which tends to yield pretty decent results, and is a good comparison.