# Personal opinion on:

### Hu, Y., Koren, Y., & Volinsky, C. (2008). Collaborative filtering for implicit feedback datasets. In Data Mining, 2008. ICDMâ€™08. Eighth IEEE International Conference on (pp. 263-272). IEEE.

In this paper, the authors discussed their approach to the building of an implicit feedback collaborative filtering recommender system. The relevance of this is, in reality, users don't tend to give explicit feedback on their preferences, and because of this, most of the times when building recommender systems, implicit feedback is the only way to go. The presented differences between implicit and explicit feedback systems (or characteristics of impicit feedback, as they are called in the paper) are really interesting, and, at least for me, weren't completely obvious at the beginning, until they were pointed out.

In a related manner, but not the same line, is the origin of the dataset they used. As it was pointed out, it was data on TV shows, but in contrast to most of the systems that are built, the data here came from specifically from TVs, and thus, the posibility for multiple users in the same device is key, making the recommendation more difficult. An interesting approach to diminish the intrinsic problems of the dataset is the implementation of diminishing returns when considering shows that were watched in the same TV channel, in a row. In actual systems that could be compared to, like Netflix, there is no such problems, because if the user falls asleep, or just doesn't bother to change the channel, in today's systems, the same show would keep running, or it would stop on it's own, but in this case, the TV just keeps playing the same channel.

Moving on into the way the model is built itself, the algebraic work to make the system linear to the input is outstanding. Along the lines of linearity, the authors expressed "Results keep improving as numbers of factors increases, till reaching rank=8.35% for 200 factors. Thus, we recommend working with the highest number of factors feasible within computational limitations". I feel like this quote could be fairly controvertial, as arbitrarily increasing the number of factors of the system may end up causing overfitting. It is pointed out that it should be increased within computational limitations, so it's probably not feasible for a system with a big dataset to reach a numbers of factors that is too high. But, let's consider the case of a big company, that relies on very few big users, and thus they can afford a lot of computational power. As the ammount of users is fairly small, and the company can afford computational power, a number of factors even bigger than users could be reached. This is a really niche and specific example, but the objective was to point out that the authors should've been more careful with that, especially since they didn't even test the system for more than 200 factors, so it is unknown if performance keeps improving with the number of factors after that.

To start closing out this opinion, I'd like to move to the last topic I found interesting in the paper: the way the authors dealt with the test dataset, and the fact that implicit feedback is, as the name implies, implicit, and thus there is no explicit way of telling if the user actually liked what was recommended to them. It would be really interesting to have a study where a model like this is applied to a control group of people, handing them the recommendations given by the system, and asking them to explicitly indicate if they either liked or disliked the recommended show. With an approach like this, it would be possible to implement more traditional ways of evaluating the performance of the system.